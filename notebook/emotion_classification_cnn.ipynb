{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d34551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb200e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.7.1+cu118\n",
      "CUDA Available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96\n",
    "IMG_CHANNELS = 1\n",
    "NUM_CLASSES = 7\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "EMOTION_LABELS = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f334bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "        transforms.RandomRotation(5),  \n",
    "        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),  \n",
    "        transforms.RandomHorizontalFlip(p=0.3),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485], std=[0.229]) \n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "\n",
    "def create_data_loaders(train_dir, val_dir, test_dir=None):\n",
    "    train_transform, val_transform = get_data_transforms()    \n",
    "    train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)  \n",
    "    val_dataset = datasets.ImageFolder(val_dir, transform=val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = None\n",
    "    if test_dir and os.path.exists(test_dir):\n",
    "        test_dataset = datasets.ImageFolder(test_dir, transform=val_transform)\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a868d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionCNN(nn.Module):    \n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout3 = nn.Dropout2d(0.3)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(64)\n",
    "        self.conv8 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv9 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(32)\n",
    "        self.conv10 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
    "        self.bn10 = nn.BatchNorm2d(16)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout4 = nn.Dropout2d(0.3)\n",
    "        \n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc1 = nn.Linear(16, 64)  \n",
    "        self.dropout5 = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.bn8(self.conv8(x)))\n",
    "        \n",
    "        x = F.relu(self.bn9(self.conv9(x)))\n",
    "        x = F.relu(self.bn10(self.conv10(x)))\n",
    "        x = self.pool4(x)\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout5(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b49a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device): \n",
    "    model.train()   \n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    train_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for data, target in train_bar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total_samples += target.size(0)\n",
    "        correct_predictions += (predicted == target).sum().item()\n",
    "        \n",
    "        train_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100.*correct_predictions/total_samples:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0   \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=\"Validation\")\n",
    "        \n",
    "        for data, target in val_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_samples += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "            \n",
    "            val_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*correct_predictions/total_samples:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=EPOCHS):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)  \n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, \n",
    "                                patience=3, min_lr=1e-6)\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    patience = 10\n",
    "    \n",
    "    print(f\"Starting training for {epochs} epochs...\")\n",
    "    print(f\"Training batches: {len(train_loader)}\")\n",
    "    print(f\"Validation batches: {len(val_loader)}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_emotion_model.pth')\n",
    "            print(f\"New best validation accuracy: {best_val_acc:.4f} - Model saved!\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('best_emotion_model.pth'))\n",
    "    print(f\"Best model loaded with validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, test_loader, class_labels=EMOTION_LABELS):\n",
    "    if test_loader is None:\n",
    "        print(\"No test data available for evaluation.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MODEL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_loader, desc=\"Testing\")\n",
    "        \n",
    "        for data, target in test_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            \n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    test_accuracy = correct / total\n",
    "    print(f\"\\nTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")    \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(\"-\" * 50)\n",
    "    report = classification_report(\n",
    "        all_targets, \n",
    "        all_predictions, \n",
    "        target_names=class_labels,\n",
    "        digits=4\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"-\" * 30)\n",
    "    cm = confusion_matrix(all_targets, all_predictions)\n",
    "    print(cm)\n",
    "    \n",
    "    return test_accuracy, report\n",
    "\n",
    "def plot_training_history(history):  \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    epochs = range(1, len(history['train_accuracy']) + 1)\n",
    "    \n",
    "    axes[0].plot(epochs, history['train_acc'], 'b-', label='Training Accuracy')\n",
    "    axes[0].plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy')\n",
    "    axes[0].set_title('Model Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    axes[1].plot(epochs, history['train_loss'], 'b-', label='Training Loss')\n",
    "    axes[1].plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n",
    "    axes[1].set_title('Model Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30fbb6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    print(\"=\"*60)\n",
    "    print(\"EMOTION DETECTION CNN MODEL - PyTorch\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Input Shape: ({IMG_CHANNELS}, {IMG_HEIGHT}, {IMG_WIDTH})\")\n",
    "    print(f\"Number of Classes: {NUM_CLASSES}\")\n",
    "    print(f\"Classes: {', '.join(EMOTION_LABELS)}\")\n",
    "    print(\"=\"*60)\n",
    "    train_dir = '../data/images/train'\n",
    "    val_dir = '../data/images/validation'\n",
    "    test_dir = '../data/images/test'\n",
    "\n",
    "    if not os.path.exists(train_dir):\n",
    "        print(f\"Warning: Training directory '{train_dir}' not found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n1. Creating data loaders with augmentation...\")\n",
    "    train_loader, val_loader, test_loader, class_names = create_data_loaders(\n",
    "        train_dir, val_dir, test_dir\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(train_loader.dataset)} training images\")\n",
    "    print(f\"Found {len(val_loader.dataset)} validation images\")\n",
    "    if test_loader:\n",
    "        print(f\"Found {len(test_loader.dataset)} test images\")\n",
    "    print(f\"Classes: {class_names}\")\n",
    "    \n",
    "    print(\"\\n2. Building CNN model...\")\n",
    "    model = EmotionCNN(num_classes=NUM_CLASSES).to(device)\n",
    "    \n",
    "    print(\"\\n3. Model Information:\")\n",
    "    print(f\"Total trainable parameters: {count_parameters(model):,}\")\n",
    "    print(f\"Model device: {next(model.parameters()).device}\")\n",
    "    \n",
    "    print(\"\\n4. Model Architecture:\")\n",
    "    print(model)\n",
    "    \n",
    "    print(\"\\n5. Training model...\")\n",
    "    history = train_model(model, train_loader, val_loader, epochs=EPOCHS)\n",
    "    \n",
    "    print(\"\\n6. Plotting training history...\")\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    if test_loader:\n",
    "        print(\"\\n7. Evaluating model on test set...\")\n",
    "        test_accuracy, report = evaluate_model(model, test_loader, class_names)\n",
    "    else:\n",
    "        print(\"\\n7. Evaluating model on validation set...\")\n",
    "        test_accuracy, report = evaluate_model(model, val_loader, class_names)\n",
    "    \n",
    "    model_save_path = 'emotion_detection_model.pth'\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_architecture': model,\n",
    "        'class_names': class_names,\n",
    "        'num_classes': NUM_CLASSES,\n",
    "    }, model_save_path)\n",
    "    print(f\"\\n8. Model saved as '{model_save_path}'\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca022bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EMOTION DETECTION CNN MODEL - PyTorch\n",
      "============================================================\n",
      "Input Shape: (1, 48, 48)\n",
      "Number of Classes: 7\n",
      "Classes: angry, disgust, fear, happy, sad, surprise, neutral\n",
      "============================================================\n",
      "\n",
      "1. Creating data loaders with augmentation...\n",
      "Found 28821 training images\n",
      "Found 7066 validation images\n",
      "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
      "\n",
      "2. Building CNN model...\n",
      "\n",
      "3. Model Information:\n",
      "Total trainable parameters: 66,423\n",
      "Model device: cuda:0\n",
      "\n",
      "4. Model Architecture:\n",
      "EmotionCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (leaky_relu1): LeakyReLU(negative_slope=0.5)\n",
      "  (conv5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout2): Dropout2d(p=0.25, inplace=False)\n",
      "  (conv6): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv7): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (leaky_relu2): LeakyReLU(negative_slope=0.5)\n",
      "  (conv8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout3): Dropout2d(p=0.25, inplace=False)\n",
      "  (conv9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout4): Dropout2d(p=0.25, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=144, out_features=100, bias=True)\n",
      "  (dropout5): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=100, out_features=7, bias=True)\n",
      ")\n",
      "\n",
      "5. Training model...\n",
      "Starting training for 50 epochs...\n",
      "Training batches: 901\n",
      "Validation batches: 221\n",
      "\n",
      "Epoch 1/50\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 901/901 [01:11<00:00, 12.56it/s, Loss=1.9273, Acc=24.65%]\n",
      "Validation: 100%|██████████| 221/221 [00:27<00:00,  7.99it/s, Loss=2.1654, Acc=25.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9179, Train Acc: 0.2465\n",
      "Val Loss: 1.9074, Val Acc: 0.2583\n",
      "New best validation accuracy: 0.2583 - Model saved!\n",
      "\n",
      "Epoch 2/50\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 901/901 [00:22<00:00, 39.50it/s, Loss=1.9273, Acc=24.86%] \n",
      "Validation: 100%|██████████| 221/221 [00:15<00:00, 13.84it/s, Loss=2.1654, Acc=25.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9169, Train Acc: 0.2486\n",
      "Val Loss: 1.9074, Val Acc: 0.2583\n",
      "\n",
      "Epoch 3/50\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 901/901 [00:23<00:00, 39.01it/s, Loss=2.0226, Acc=24.86%] \n",
      "Validation: 100%|██████████| 221/221 [00:16<00:00, 13.68it/s, Loss=2.1654, Acc=25.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9169, Train Acc: 0.2486\n",
      "Val Loss: 1.9074, Val Acc: 0.2583\n",
      "\n",
      "Epoch 4/50\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 901/901 [00:22<00:00, 39.52it/s, Loss=1.8321, Acc=24.86%] \n",
      "Validation: 100%|██████████| 221/221 [00:16<00:00, 13.65it/s, Loss=2.1654, Acc=25.83%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9168, Train Acc: 0.2486\n",
      "Val Loss: 1.9074, Val Acc: 0.2583\n",
      "\n",
      "Epoch 5/50\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 901/901 [00:23<00:00, 37.62it/s, Loss=1.9749, Acc=24.86%] \n",
      "Validation: 100%|██████████| 221/221 [00:28<00:00,  7.77it/s, Loss=2.1654, Acc=25.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9169, Train Acc: 0.2486\n",
      "Val Loss: 1.9074, Val Acc: 0.2583\n",
      "\n",
      "Epoch 6/50\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▊| 888/901 [01:00<00:00, 14.71it/s, Loss=1.9154, Acc=24.86%]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m5. Training model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m history = train_model(model, train_loader, val_loader, epochs=EPOCHS)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m6. Plotting training history...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m plot_training_history(history)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 88\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n\u001b[32m     90\u001b[39m val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n\u001b[32m     92\u001b[39m scheduler.step(val_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m      5\u001b[39m total_samples = \u001b[32m0\u001b[39m\n\u001b[32m      7\u001b[39m train_bar = tqdm(train_loader, desc=\u001b[33m\"\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m train_bar:\n\u001b[32m     10\u001b[39m     data, target = data.to(device), target.to(device)\n\u001b[32m     12\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MufliDevs\\anaconda3\\envs\\emotion_torch\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[32m   1182\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[32m   1183\u001b[39m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[32m   1184\u001b[39m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MufliDevs\\anaconda3\\envs\\emotion_torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MufliDevs\\anaconda3\\envs\\emotion_torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28mself\u001b[39m._get_data()\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MufliDevs\\anaconda3\\envs\\emotion_torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1443\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m         success, data = \u001b[38;5;28mself\u001b[39m._try_get_data()\n\u001b[32m   1444\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1445\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MufliDevs\\anaconda3\\envs\\emotion_torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28mself\u001b[39m._data_queue.get(timeout=timeout)\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MufliDevs\\anaconda3\\envs\\emotion_torch\\Lib\\queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28mself\u001b[39m.not_empty.wait(remaining)\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MufliDevs\\anaconda3\\envs\\emotion_torch\\Lib\\threading.py:331\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    333\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
